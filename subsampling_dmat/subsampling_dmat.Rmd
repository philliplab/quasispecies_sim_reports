---
title: Subsampling dmat
output: 
  bookdown::gitbook:
    config:
      toc:
        collapse: subsection
      sharing:
        facebook: no
        twitter: no
      fontsettings:
        theme: sepia
---

```{r, include=FALSE}
library(yasss)
library(knitr)
library(rmarkdown)
library(tidyr)

knitr::opts_chunk$set(echo = FALSE,
                      base.dir = "/home/phillipl/projects/quasispecies_sim_reports/builds/subsampling_dmat/figures")
options(scipen = 99)
setCacheDir("/home/phillipl/projects/quasispecies_sim_reports/builds/subsampling_dmat/simpleCache")
set.seed(1)
source('../utilities/reporting_utilities.R')
```

```{r debugging-chunk, eval = FALSE}
yasss:::restart_r()
```

# Subsampling dmat

## Description

Storing large distance matrices consumes too much memory.

Can you subsample say 1 million observations from a distance matrix and discard everything else and still get a highly accurate density plot, decile estimates and average pairwise distance estimates?

The computational code block is set to not evaluate since it takes so long to run. The default way to use this report is to just load precomputed results.

```{r, include=FALSE, eval = FALSE}
args1 <- list(
  ancestors = paste(rep("A", 500), collapse = ''),
  r0 = 2,
  n_gen = 14,
  n_pop = Inf,
  mutator = list(fun = "mutator_uniform_fun",
                 args = list(mu = 1/250)),
  fitness_evaluator = list(fun = "fitness_evaluator_homology_fun",
                           args = list(comparators = paste(rep('XXXXA', 100), collapse = ''),
                                       h2fs = "h2fs_univariate_linear_fun"))
)

make_comp_df <- function(x, label = 1){
  last_gen <- x %>% filter(gen_num == max(gen_num))

  ltm <- proc.time()
  dmat <- stringdistmatrix(last_gen$the_seq, method = 'hamming')
  calc_time <- (proc.time() - ltm)[1]
  
  dmat_comp_tab <- data.frame(label = numeric(0),
                              size = numeric(0),
                              avg_hd = numeric(0),
                              p000 = numeric(0),
                              p010 = numeric(0),
                              p020 = numeric(0),
                              p030 = numeric(0),
                              p040 = numeric(0),
                              p050 = numeric(0),
                              p060 = numeric(0),
                              p070 = numeric(0),
                              p080 = numeric(0),
                              p090 = numeric(0),
                              p100 = numeric(0)
                              )
  
  avg_hd <- mean(dmat)
  deciles <- t(data.frame(quantile(dmat, (0:10)/10, type = 4)))
  names(deciles) <- c("p000", "p010", "p020", "p030", "p040", "p050", "p060",
                      "p070", "p080", "p090", "p100")
  row.names(deciles) <- NULL
  dmat_comp_tab <- rbind(dmat_comp_tab,
                         cbind(data.frame(label = label,
                                          size = length(dmat), 
                                          avg_hd = avg_hd,
                                          calc_time = calc_time),
                               deciles))
  
  for (i in 4:8){
    print(i)
    if (10^i < length(dmat)){
      subsam <- sample(as.numeric(dmat), 10^i)
      avg_hd <- mean(subsam)
      deciles <- t(data.frame(quantile(subsam, (0:10)/10, type = 4)))
      names(deciles) <- c("p000", "p010", "p020", "p030", "p040", "p050", "p060",
                          "p070", "p080", "p090", "p100")
      row.names(deciles) <- NULL
      dmat_comp_tab <- rbind(dmat_comp_tab,
                             cbind(data.frame(label = label,
                                              size = i, 
                                              avg_hd = avg_hd,
                                              calc_time = 0),
                                   deciles))
    }
  }
  i <- 1000
  for (i in c(100, 500, 1000, 2000, 5000, 10000)){
    if (i < length(last_gen$the_seq)){
      c_the_seq <- sample(last_gen$the_seq, i, replace = FALSE)
      ltm <- proc.time()
      c_dmat <- stringdistmatrix(c_the_seq, method = 'hamming')
      calc_time <- (proc.time() - ltm)[1]
      subsam <- as.numeric(c_dmat)
      avg_hd <- mean(subsam)
      deciles <- t(data.frame(quantile(subsam, (0:10)/10, type = 4)))
      names(deciles) <- c("p000", "p010", "p020", "p030", "p040", "p050", "p060",
                          "p070", "p080", "p090", "p100")
      row.names(deciles) <- NULL
      dmat_comp_tab <- rbind(dmat_comp_tab,
                             cbind(data.frame(label = label,
                                              size = i, 
                                              avg_hd = avg_hd,
                                              calc_time = calc_time),
                                   deciles))
    }
  }
  return(dmat_comp_tab)
}

dmat_comp_tab <- NULL
for (i in 1:10){
  print(paste("==== ", i, " ====", sep = ''))
  x <- memoiseCache(fun = 'sim_pop', args = args1, cacheName = 'subsampling_dmat', 
                    seed = i)
  dmat_comp_tab <- rbind(dmat_comp_tab, make_comp_df(x, i))
}

print(dmat_comp_tab)
names(dmat_comp_tab) <- c("label", "size", "avg_hd", "calc_time", "X0.",
                          "X10.", "X20.", "X30.", "X40.", "X50.", "X60.",
                          "X70.", "X80.", "X90.", "X100.")

#write.csv(dmat_comp_tab, "/home/phillipl/projects/quasispecies_sim_reports/builds/subsampling_dmat/dmat_comp_tab_gen13_n10.csv", row.names = FALSE)
#write.csv(dmat_comp_tab, "/home/phillipl/projects/quasispecies_sim_reports/builds/subsampling_dmat/dmat_comp_tab_gen14_n10.csv", row.names = FALSE)
```

What about subsampling on the sequences to speed up the computation of the distance matrix?

Note that in practice we will always subsample down to at most 5000 since that is the limitation of the sequencing.

Some plots comparing the distance summaries

```{r}
dmat_comp_tab <- read.csv("/home/phillipl/projects/quasispecies_sim_reports/builds/subsampling_dmat/dmat_comp_tab_gen14_n10.csv")

normalized_tab <- dmat_comp_tab[0,]
i <- unique(dmat_comp_tab$label)[1]
for (i in unique(dmat_comp_tab$label)){
  c_rows <- dmat_comp_tab %>% filter(label == i)
  new_rows <- c_rows[2:nrow(c_rows),]
  new_rows[,c(-1,-2)] <- c_rows[2:nrow(c_rows),c(-1,-2)]/c_rows[rep(1, nrow(c_rows)-1),c(-1,-2)]
  normalized_tab <- rbind(normalized_tab,
                          new_rows)
}

kable(
metrics_tab <-
normalized_tab %>% 
  group_by(size) %>%
  summarize(avg = mean(avg_hd-1),
            sd = sd(avg_hd),
            calc_time = mean(calc_time),
            sd_10 = sd(X10.),
            sd_50 = sd(X50.),
            sd_90 = sd(X90.))
)

long_metrics_tab <-
gather(metrics_tab, metric, value, -size)
```

```{r fig.height=14, fig.width=5}
ggplot(long_metrics_tab, aes(x = as.factor(size), y = value)) +
  geom_bar(stat = 'identity') +
  facet_grid(rows = vars(metric), scales = 'free')
```

Investigating the caching of distance matrices. Massive speed up and a 14gen dmat only uses 110MB so cache'em from now on.

```{r}
#time_comp_dmat <- NULL
#
#for (i in 1:10){
#  ltm <- proc.time()
#  x <- memoiseCache(fun = 'sim_pop', args = args1, cacheName = 'subsampling_dmat', 
#                    seed = i)
#  genea_time <- (proc.time() - ltm)[1]
#  
#  last_gen <- x %>% filter(gen_num == max(gen_num))
#  ltm <- proc.time()
#  dmat <- memoiseCache(fun = 'stringdistmatrix',
#                       args = list(last_gen$the_seq, method = 'hamming'),
#                       cacheName = 'an_actual_dmat',
#                       seed = i)
#  dmat_time <- (proc.time() - ltm)[1]
#  
#  ltm <- proc.time()
#  dmat <- memoiseCache(fun = 'stringdistmatrix',
#                       args = list(last_gen$the_seq, method = 'hamming'),
#                       cacheName = 'an_actual_dmat',
#                       seed = i)
#  load_time <- (proc.time() - ltm)[1]
#
#  time_comp_dmat <- rbind(time_comp_dmat,
#                          data.frame(genea_time = genea_time,
#                                     dmat_time = dmat_time,
#                                     load_time = load_time))
#}
#
#print(time_comp_dmat)

time_comp_dmat <-structure(list(genea_time = c(0.0879999999997381, 0.0840000000007421,
0.091999999998734, 0.0879999999997381, 0.091999999998734, 0.0879999999997381,
0.092000000000553, 0.100000000000364, 0.0959999999995489, 0.0879999999997381
), dmat_time = c(550.484, 543.156000000001, 546.072, 546.172,
544.296, 556.444, 565.960000000001, 545.915999999999, 565.544,
551.843999999999), load_time = c(3.33200000000033, 3.37199999999939,
3.35199999999895, 3.36800000000039, 3.34799999999996, 3.65200000000004,
3.61599999999999, 3.48400000000038, 3.64400000000023, 3.44399999999951
)), .Names = c("genea_time", "dmat_time", "load_time"), row.names = c("user.self",
"user.self1", "user.self2", "user.self3", "user.self4", "user.self5",
"user.self6", "user.self7", "user.self8", "user.self9"), class = "data.frame")

kable(time_comp_dmat)
```
