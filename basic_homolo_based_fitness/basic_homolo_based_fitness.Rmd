---
title: Basic homology based fitness
output: 
  html_document:
    toc: false
    theme: cerulean
---

```{r, include=FALSE}
library(yasss)
library(knitr)
library(rmarkdown)
library(tidyr)

knitr::opts_chunk$set(echo = FALSE,
                      base.dir = "/home/phillipl/projects/quasispecies_sim_reports/builds/basic_homolo_based_fitness/figures")
options(scipen = 99)
setCacheDir("/home/phillipl/projects/quasispecies_sim_reports/builds/basic_homolo_based_fitness/simpleCache")
source('../utilities/reporting_utilities.R')

report_start_time <- proc.time()
```

```{r debugging-chunk, eval = FALSE}
getwd()
yasss:::restart_r()
setwd('/home/phillipl/projects/quasispecies_sim_reports/repo/quasispecies_sim_reports/basic_homolo_based_fitness')
library(profvis)
```

## Description

### Data generation

A first basic report exploring the effects of assigning fitness based on
homology.

The ancestral sequence is specified as a sequence of only As.

A (very unrealistic) epitope is then specified as a sequence in which every 5th
character is an A.

The fitness is based on the number of matches between the epitope and the
sequence. A fitness of zero is assigned if the sequence perfectly matches the
epitope and a fitness of one is assigned if there is no match at any point. For
sequences that does neither perfectly match the epitope nor perfectly mismatch
the epitope, fitness is assigned linearly beased on the number of matches.

Using this epitope, multiple pairs of datasets were generated. This number is
stated below in the tables tracking the number of simulations.

First the entire quasispecies was simulated without taking fitness into
account. Then, a copy is made of this genealogy and all individuals across all
generations (excluding the first x generations) that has a fitness score lower
than a cutoff were identified. These unfit individuals and ALL their decendents
were then removed from the genealogy. The remaining individuals in the last
generation of this dataset were then selected as a dataset.

To construct the partner of the dataset described above, a number of
individuals are randomly selected from the last generation independent of any
fitness considerations so that the same number of sequences are in each
dataset.

This process was repeated to generate the same number of pairs again, but with
an epitope based on Cs. In this case instead of letting every 5th letter be an
A, we used a C instead.

### A-based epitope

Since the ancestor perfectly matches the epitope, this produced a very high
level of pressure.

The fitness requirement was set to 0.02. Given that the sequences are of length
500 and every 5th letter was part of the epitope, the epitope contains 100
positions. From the linear nature of the way fitness is computed, the fitness
requirement of 0.02 translates to 2 positions. So if the sequence has non-As at
more than 2 of the 100 epitope positions, then the sequence will be seen as
fit.

This mimics a scenario in which the transmitted founder is sensitive to VRC01.

### C-based epitope

Since the ancestor perfectly mismatches the epitope, this produced a very low
level of pressure.

The fitness requirement was set to 0.97. Given that the sequences are of length
500 and every 5th letter was part of the epitope, the epitope contains 100
positions. From the linear nature of the way fitness is computed, the fitness
requirement of 0.97 translates to 97 positions. So if the sequence has non-As at
more than 97 of the 100 epitope positions, then the sequence will be seen as
fit.

This mimics a scenario in which the transmitted founder is resistant to VRC01.

## Interpretation

This report highlights two points:

**TODO**

## Designs for more a more useful version of fitness

How to modify the fitness computation to be more useful in such a way that it
is easy to implement with the current tools?

What if we add in a more realistic epitope: Just 20 positions with some
mismatches to the ancestor.  Then, together with this we need to constrict the
space of viable sequences. To do this, add another 'epitope' consisting of
about 200 positions and let a match on this yield a positive fitness. Thus the
fitness computation becomes: The percentage of matches to the positive epitope
less the percentage of matches to the negative epitope.

Then, should fitness be interpreted probabilistically? Does a fitness of 50%
give you a 50% chance of surviving? Or do we use a cutoff?

Obviously this is still simplifications. Ideally, this will be based on amino
acids and the 'positivie fitness epitope' will allow different, but not all,
letters at certain positions. However, this is a bit more work to implement, so
hold off on this for now.

It will be better to just extract the values from LANL and mimic the real deal.

```{r, include=FALSE}
n_gen <- 12
n_sims <- 20
n_gen_with_perfect_fitness <- 5
max_dmat_size <- 200

arg_set1 <- list(
  label = 'A',
  ancestors = paste(rep("A", 500), collapse = ''),
  r0 = 2,
  n_gen = n_gen,
  n_pop = Inf,
  mutator = list(fun = "mutator_uniform_fun",
                 args = list(mu = 1/250)),
  fitness_evaluator = list(fun = "fitness_evaluator_homology_fun",
                           args = list(comparators = paste(rep('XXXXA', 100), collapse = ''),
                                       h2fs = "h2fs_univariate_linear_fun")),
  required_fitness = 0.02
)

arg_set2 <- list(
  label = 'C',
  ancestors = paste(rep("A", 500), collapse = ''),
  r0 = 2,
  n_gen = n_gen,
  n_pop = Inf,
  mutator = list(fun = "mutator_uniform_fun",
                 args = list(mu = 1/250)),
  fitness_evaluator = list(fun = "fitness_evaluator_homology_fun",
                           args = list(comparators = paste(rep('XXXXC', 100), collapse = ''),
                                       h2fs = "h2fs_univariate_linear_fun")),
  required_fitness = 0.97
)

arg_collection <- list(arg_set1, arg_set2)

output_dmat <- TRUE
output_dmat <- FALSE

many_pops <- sim_proc_many_pops(arg_collection, n_sims=n_sims, 
                                output_dmat = output_dmat,
                                fitness_processing = 'fit_unfit_pair', 
                                n_gen_with_perfect_fitness = n_gen_with_perfect_fitness,
                                max_dmat_size = max_dmat_size, 
                                verbose = TRUE)
```

```{r exploring-clusters, eval = FALSE}
x <- many_pops$all_dmats[[1]]

z <- as.matrix(x$dmat)
y <- clara(z, 2)
cluster1 <- which(y$clustering==1)
cluster2 <- which(y$clustering==2)

within_cluster <- c(as.vector(z[cluster1, cluster1]), as.vector(z[cluster2, cluster2]))
between_cluster <- c(as.vector(z[cluster1, cluster2]), as.vector(z[cluster2, cluster1]))

mean(within_cluster)
mean(between_cluster)

cluster_sizes <- c(length(cluster1), length(cluster2))
```


### Some parameters:

Number of generations: `r n_gen`

Number of pairs simulated for each scenario: `r n_sims`

Number of initial generations with artificially assigned perfect fitness: `r n_gen_with_perfect_fitness`

Maximum number of sequences considered when a distance matrix is produced: `r max_dmat_size`

## Simulation Results

```{r test-child, child = '../utilities/comp_sim_chunk.Rmd'}
```

## Total Running Time
```{r}
print(proc.time() - report_start_time)
```

```{r, eval = TRUE, include = FALSE}
save.image('/tmp/basic_homolo.RData')
```

